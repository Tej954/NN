{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "pXsZta5oi4bT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YxsCIzqf4bB",
        "outputId": "ca7ad488-38a3-4709-d71a-8652d7f4daf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6166\n",
            "Epoch 100, Loss: 0.0277\n",
            "Epoch 200, Loss: 0.0009\n",
            "Epoch 300, Loss: 0.0000\n",
            "Epoch 400, Loss: 0.0000\n",
            "Epoch 500, Loss: 0.0000\n",
            "Epoch 600, Loss: 0.0000\n",
            "Epoch 700, Loss: 0.0000\n",
            "Epoch 800, Loss: 0.0000\n",
            "Epoch 900, Loss: 0.0000\n",
            "Predictions: [[8.4659638e-07]\n",
            " [9.9999946e-01]\n",
            " [9.9999940e-01]\n",
            " [3.3605588e-07]]\n"
          ]
        }
      ],
      "source": [
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Define the architecture of the neural network\n",
        "input_size = 2  # Number of input features\n",
        "hidden_size = 3  # Number of neurons in the hidden layer\n",
        "output_size = 1  # Number of output neurons\n",
        "\n",
        "# Define placeholders for input and output data\n",
        "X = tf.placeholder(tf.float32, shape=[None, input_size], name='X')\n",
        "y = tf.placeholder(tf.float32, shape=[None, output_size], name='y')\n",
        "\n",
        "# Define the weights and biases for the hidden layer\n",
        "W_hidden = tf.Variable(tf.random_normal([input_size, hidden_size]), name='W_hidden')\n",
        "b_hidden = tf.Variable(tf.zeros([hidden_size]), name='b_hidden')\n",
        "\n",
        "# Define the weights and biases for the output layer\n",
        "W_output = tf.Variable(tf.random_normal([hidden_size, output_size]), name='W_output')\n",
        "b_output = tf.Variable(tf.zeros([output_size]), name='b_output')\n",
        "\n",
        "# Define the operations for the hidden layer\n",
        "hidden_output = tf.nn.relu(tf.add(tf.matmul(X, W_hidden), b_hidden))\n",
        "\n",
        "# Define the operations for the output layer\n",
        "output = tf.add(tf.matmul(hidden_output, W_output), b_output)\n",
        "\n",
        "# Define the loss function (mean squared error)\n",
        "loss = tf.reduce_mean(tf.square(output - y))\n",
        "\n",
        "# Define the optimizer (Gradient Descent)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train_op = optimizer.minimize(loss)\n",
        "\n",
        "# Create some example data\n",
        "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_train = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "# Create a TensorFlow session and train the network\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Train the network for 1000 epochs\n",
        "    for epoch in range(1000):\n",
        "        _, current_loss = sess.run([train_op, loss], feed_dict={X: X_train, y: y_train})\n",
        "        if epoch % 100 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {current_loss:.4f}')\n",
        "\n",
        "    # Make predictions on the training data\n",
        "    predictions = sess.run(output, feed_dict={X: X_train})\n",
        "    print(\"Predictions:\", predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In the above  code:\n",
        "\n",
        "#We have defined the architecture of a simple feedforward neural network with one hidden layer.\n",
        "#We have used TensorFlow to define placeholders for input and output data, as well as variables for weights and biases.\n",
        "#We have defined the operations for the hidden and output layers using the ReLU activation function.\n",
        "#We have defined the loss function as mean squared error and use gradient descent to optimize the weights and biases.\n",
        "#We have created example data (X_train and y_train) representing the XOR function.\n",
        "#We have trained the network for 1000 epochs and print the loss at every 100th epoch.\n",
        "#Finally, we have made  predictions on the training data and print the results."
      ],
      "metadata": {
        "id": "wY4n7lidjQnF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cF2G4yNkEAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}